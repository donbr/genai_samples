{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/microsoft/autogen/blob/main/notebook/agentchat_qdrant_RetrieveChat.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"toc\"></a>\n",
    "# Using RetrieveChat with Qdrant for Retrieve Augmented Code Generation and Question Answering\n",
    "\n",
    "[Qdrant](https://qdrant.tech/) is a high-performance vector search engine/database.\n",
    "\n",
    "This notebook demonstrates the usage of `QdrantRetrieveUserProxyAgent` for RAG, based on [agentchat_RetrieveChat.ipynb](https://colab.research.google.com/github/microsoft/autogen/blob/main/notebook/agentchat_RetrieveChat.ipynb).\n",
    "\n",
    "\n",
    "RetrieveChat is a conversational system for retrieve augmented code generation and question answering. In this notebook, we demonstrate how to utilize RetrieveChat to generate code and answer questions based on customized documentations that are not present in the LLM's training dataset. RetrieveChat uses the `RetrieveAssistantAgent` and `QdrantRetrieveUserProxyAgent`, which is similar to the usage of `AssistantAgent` and `UserProxyAgent` in other notebooks (e.g., [Automated Task Solving with Code Generation, Execution & Debugging](https://github.com/microsoft/autogen/blob/main/notebook/agentchat_auto_feedback_from_code_execution.ipynb)).\n",
    "\n",
    "We'll demonstrate usage of RetrieveChat with Qdrant for code generation and question answering w/ human feedback.\n",
    "\n",
    "\n",
    "## Requirements\n",
    "\n",
    "AutoGen requires `Python>=3.8`. To run this notebook example, please install the [retrievechat] option.\n",
    "```bash\n",
    "pip install \"pyautogen[retrievechat]>=0.2.3\" \"flaml[automl]\" \"qdrant_client[fastembed]\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyautogen>=0.2.3 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from pyautogen[retrievechat]>=0.2.3) (0.2.11)\n",
      "Requirement already satisfied: flaml[automl] in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (2.1.1)\n",
      "Requirement already satisfied: qdrant_client[fastembed] in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (1.7.2)\n",
      "Requirement already satisfied: diskcache in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from pyautogen>=0.2.3->pyautogen[retrievechat]>=0.2.3) (5.6.3)\n",
      "Requirement already satisfied: docker in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from pyautogen>=0.2.3->pyautogen[retrievechat]>=0.2.3) (7.0.0)\n",
      "Requirement already satisfied: openai>=1.3 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from pyautogen>=0.2.3->pyautogen[retrievechat]>=0.2.3) (1.11.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.10 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from pyautogen>=0.2.3->pyautogen[retrievechat]>=0.2.3) (2.6.1)\n",
      "Requirement already satisfied: python-dotenv in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from pyautogen>=0.2.3->pyautogen[retrievechat]>=0.2.3) (1.0.1)\n",
      "Requirement already satisfied: termcolor in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from pyautogen>=0.2.3->pyautogen[retrievechat]>=0.2.3) (2.4.0)\n",
      "Requirement already satisfied: tiktoken in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from pyautogen>=0.2.3->pyautogen[retrievechat]>=0.2.3) (0.5.2)\n",
      "Requirement already satisfied: NumPy>=1.17.0rc1 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from flaml[automl]) (1.26.4)\n",
      "Requirement already satisfied: lightgbm>=2.3.1 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from flaml[automl]) (4.3.0)\n",
      "Requirement already satisfied: xgboost>=0.90 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from flaml[automl]) (2.0.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from flaml[automl]) (1.12.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from flaml[automl]) (2.2.0)\n",
      "Requirement already satisfied: scikit-learn>=0.24 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from flaml[automl]) (1.4.0)\n",
      "Requirement already satisfied: grpcio>=1.41.0 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from qdrant_client[fastembed]) (1.60.1)\n",
      "Requirement already satisfied: grpcio-tools>=1.41.0 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from qdrant_client[fastembed]) (1.60.1)\n",
      "Requirement already satisfied: httpx>=0.14.0 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from httpx[http2]>=0.14.0->qdrant_client[fastembed]) (0.26.0)\n",
      "Requirement already satisfied: portalocker<3.0.0,>=2.7.0 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from qdrant_client[fastembed]) (2.8.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.26.14 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from qdrant_client[fastembed]) (2.2.0)\n",
      "Requirement already satisfied: fastembed==0.1.1 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from qdrant_client[fastembed]) (0.1.1)\n",
      "Requirement already satisfied: onnx<2.0,>=1.11 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from fastembed==0.1.1->qdrant_client[fastembed]) (1.15.0)\n",
      "Requirement already satisfied: onnxruntime<2.0,>=1.15 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from fastembed==0.1.1->qdrant_client[fastembed]) (1.17.0)\n",
      "Requirement already satisfied: requests<3.0,>=2.31 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from fastembed==0.1.1->qdrant_client[fastembed]) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.14,>=0.13 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from fastembed==0.1.1->qdrant_client[fastembed]) (0.13.3)\n",
      "Requirement already satisfied: tqdm<5.0,>=4.65 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from fastembed==0.1.1->qdrant_client[fastembed]) (4.66.1)\n",
      "Requirement already satisfied: chromadb in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from pyautogen[retrievechat]>=0.2.3) (0.4.22)\n",
      "Requirement already satisfied: ipython in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from pyautogen[retrievechat]>=0.2.3) (8.21.0)\n",
      "Requirement already satisfied: pypdf in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from pyautogen[retrievechat]>=0.2.3) (4.0.1)\n",
      "Requirement already satisfied: sentence-transformers in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from pyautogen[retrievechat]>=0.2.3) (2.3.1)\n",
      "Requirement already satisfied: protobuf<5.0dev,>=4.21.6 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from grpcio-tools>=1.41.0->qdrant_client[fastembed]) (4.25.2)\n",
      "Requirement already satisfied: setuptools in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from grpcio-tools>=1.41.0->qdrant_client[fastembed]) (68.2.2)\n",
      "Requirement already satisfied: anyio in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from httpx>=0.14.0->httpx[http2]>=0.14.0->qdrant_client[fastembed]) (3.7.1)\n",
      "Requirement already satisfied: certifi in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from httpx>=0.14.0->httpx[http2]>=0.14.0->qdrant_client[fastembed]) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from httpx>=0.14.0->httpx[http2]>=0.14.0->qdrant_client[fastembed]) (1.0.2)\n",
      "Requirement already satisfied: idna in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from httpx>=0.14.0->httpx[http2]>=0.14.0->qdrant_client[fastembed]) (3.6)\n",
      "Requirement already satisfied: sniffio in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from httpx>=0.14.0->httpx[http2]>=0.14.0->qdrant_client[fastembed]) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.14.0->httpx[http2]>=0.14.0->qdrant_client[fastembed]) (0.14.0)\n",
      "Requirement already satisfied: h2<5,>=3 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from httpx[http2]>=0.14.0->qdrant_client[fastembed]) (4.1.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from openai>=1.3->pyautogen>=0.2.3->pyautogen[retrievechat]>=0.2.3) (1.9.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from openai>=1.3->pyautogen>=0.2.3->pyautogen[retrievechat]>=0.2.3) (4.9.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from pandas>=1.1.4->flaml[automl]) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from pandas>=1.1.4->flaml[automl]) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from pandas>=1.1.4->flaml[automl]) (2023.4)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from pydantic<3,>=1.10->pyautogen>=0.2.3->pyautogen[retrievechat]>=0.2.3) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.2 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from pydantic<3,>=1.10->pyautogen>=0.2.3->pyautogen[retrievechat]>=0.2.3) (2.16.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from scikit-learn>=0.24->flaml[automl]) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from scikit-learn>=0.24->flaml[automl]) (3.2.0)\n",
      "Requirement already satisfied: build>=1.0.3 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from chromadb->pyautogen[retrievechat]>=0.2.3) (1.0.3)\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.3 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from chromadb->pyautogen[retrievechat]>=0.2.3) (0.7.3)\n",
      "Requirement already satisfied: fastapi>=0.95.2 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from chromadb->pyautogen[retrievechat]>=0.2.3) (0.104.1)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb->pyautogen[retrievechat]>=0.2.3) (0.22.0)\n",
      "Requirement already satisfied: posthog>=2.4.0 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from chromadb->pyautogen[retrievechat]>=0.2.3) (3.4.0)\n",
      "Requirement already satisfied: pulsar-client>=3.1.0 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from chromadb->pyautogen[retrievechat]>=0.2.3) (3.4.0)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from chromadb->pyautogen[retrievechat]>=0.2.3) (1.22.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from chromadb->pyautogen[retrievechat]>=0.2.3) (1.22.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from chromadb->pyautogen[retrievechat]>=0.2.3) (0.43b0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from chromadb->pyautogen[retrievechat]>=0.2.3) (1.22.0)\n",
      "Requirement already satisfied: pypika>=0.48.9 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from chromadb->pyautogen[retrievechat]>=0.2.3) (0.48.9)\n",
      "Requirement already satisfied: overrides>=7.3.1 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from chromadb->pyautogen[retrievechat]>=0.2.3) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from chromadb->pyautogen[retrievechat]>=0.2.3) (6.1.1)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from chromadb->pyautogen[retrievechat]>=0.2.3) (4.1.2)\n",
      "Requirement already satisfied: typer>=0.9.0 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from chromadb->pyautogen[retrievechat]>=0.2.3) (0.9.0)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from chromadb->pyautogen[retrievechat]>=0.2.3) (29.0.0)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from chromadb->pyautogen[retrievechat]>=0.2.3) (8.2.3)\n",
      "Requirement already satisfied: PyYAML>=6.0.0 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from chromadb->pyautogen[retrievechat]>=0.2.3) (6.0.1)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from chromadb->pyautogen[retrievechat]>=0.2.3) (4.1.0)\n",
      "Requirement already satisfied: packaging>=14.0 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from docker->pyautogen>=0.2.3->pyautogen[retrievechat]>=0.2.3) (23.2)\n",
      "Requirement already satisfied: decorator in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from ipython->pyautogen[retrievechat]>=0.2.3) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from ipython->pyautogen[retrievechat]>=0.2.3) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from ipython->pyautogen[retrievechat]>=0.2.3) (0.1.6)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from ipython->pyautogen[retrievechat]>=0.2.3) (3.0.42)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from ipython->pyautogen[retrievechat]>=0.2.3) (2.17.2)\n",
      "Requirement already satisfied: stack-data in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from ipython->pyautogen[retrievechat]>=0.2.3) (0.6.2)\n",
      "Requirement already satisfied: traitlets>=5 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from ipython->pyautogen[retrievechat]>=0.2.3) (5.14.1)\n",
      "Requirement already satisfied: exceptiongroup in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from ipython->pyautogen[retrievechat]>=0.2.3) (1.2.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from ipython->pyautogen[retrievechat]>=0.2.3) (4.9.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.32.0 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from sentence-transformers->pyautogen[retrievechat]>=0.2.3) (4.33.3)\n",
      "Requirement already satisfied: torch>=1.11.0 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from sentence-transformers->pyautogen[retrievechat]>=0.2.3) (2.2.0)\n",
      "Requirement already satisfied: nltk in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from sentence-transformers->pyautogen[retrievechat]>=0.2.3) (3.8.1)\n",
      "Requirement already satisfied: sentencepiece in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from sentence-transformers->pyautogen[retrievechat]>=0.2.3) (0.1.99)\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from sentence-transformers->pyautogen[retrievechat]>=0.2.3) (0.20.3)\n",
      "Requirement already satisfied: Pillow in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from sentence-transformers->pyautogen[retrievechat]>=0.2.3) (10.2.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from tiktoken->pyautogen>=0.2.3->pyautogen[retrievechat]>=0.2.3) (2023.12.25)\n",
      "Requirement already satisfied: pyproject_hooks in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from build>=1.0.3->chromadb->pyautogen[retrievechat]>=0.2.3) (1.0.0)\n",
      "Requirement already satisfied: tomli>=1.1.0 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from build>=1.0.3->chromadb->pyautogen[retrievechat]>=0.2.3) (2.0.1)\n",
      "Requirement already satisfied: starlette<0.28.0,>=0.27.0 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from fastapi>=0.95.2->chromadb->pyautogen[retrievechat]>=0.2.3) (0.27.0)\n",
      "Requirement already satisfied: hyperframe<7,>=6.0 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from h2<5,>=3->httpx[http2]>=0.14.0->qdrant_client[fastembed]) (6.0.1)\n",
      "Requirement already satisfied: hpack<5,>=4.0 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from h2<5,>=3->httpx[http2]>=0.14.0->qdrant_client[fastembed]) (4.0.0)\n",
      "Requirement already satisfied: filelock in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers->pyautogen[retrievechat]>=0.2.3) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers->pyautogen[retrievechat]>=0.2.3) (2024.2.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from jedi>=0.16->ipython->pyautogen[retrievechat]>=0.2.3) (0.8.3)\n",
      "Requirement already satisfied: six>=1.9.0 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb->pyautogen[retrievechat]>=0.2.3) (1.16.0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb->pyautogen[retrievechat]>=0.2.3) (2.27.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb->pyautogen[retrievechat]>=0.2.3) (1.7.0)\n",
      "Requirement already satisfied: requests-oauthlib in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb->pyautogen[retrievechat]>=0.2.3) (1.3.1)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb->pyautogen[retrievechat]>=0.2.3) (3.2.2)\n",
      "Requirement already satisfied: coloredlogs in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from onnxruntime<2.0,>=1.15->fastembed==0.1.1->qdrant_client[fastembed]) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from onnxruntime<2.0,>=1.15->fastembed==0.1.1->qdrant_client[fastembed]) (23.5.26)\n",
      "Requirement already satisfied: sympy in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from onnxruntime<2.0,>=1.15->fastembed==0.1.1->qdrant_client[fastembed]) (1.12)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from opentelemetry-api>=1.2.0->chromadb->pyautogen[retrievechat]>=0.2.3) (1.2.14)\n",
      "Requirement already satisfied: importlib-metadata<7.0,>=6.0 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from opentelemetry-api>=1.2.0->chromadb->pyautogen[retrievechat]>=0.2.3) (6.11.0)\n",
      "Requirement already satisfied: backoff<3.0.0,>=1.10.0 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->pyautogen[retrievechat]>=0.2.3) (2.2.1)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->pyautogen[retrievechat]>=0.2.3) (1.62.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.22.0 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->pyautogen[retrievechat]>=0.2.3) (1.22.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.22.0 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->pyautogen[retrievechat]>=0.2.3) (1.22.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.43b0 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->pyautogen[retrievechat]>=0.2.3) (0.43b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.43b0 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->pyautogen[retrievechat]>=0.2.3) (0.43b0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.43b0 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->pyautogen[retrievechat]>=0.2.3) (0.43b0)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.43b0 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->pyautogen[retrievechat]>=0.2.3) (0.43b0)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from opentelemetry-instrumentation==0.43b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->pyautogen[retrievechat]>=0.2.3) (1.16.0)\n",
      "Requirement already satisfied: asgiref~=3.0 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from opentelemetry-instrumentation-asgi==0.43b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->pyautogen[retrievechat]>=0.2.3) (3.7.2)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from pexpect>4.3->ipython->pyautogen[retrievechat]>=0.2.3) (0.7.0)\n",
      "Requirement already satisfied: monotonic>=1.5 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from posthog>=2.4.0->chromadb->pyautogen[retrievechat]>=0.2.3) (1.6)\n",
      "Requirement already satisfied: wcwidth in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython->pyautogen[retrievechat]>=0.2.3) (0.2.13)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from requests<3.0,>=2.31->fastembed==0.1.1->qdrant_client[fastembed]) (3.3.2)\n",
      "Requirement already satisfied: networkx in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers->pyautogen[retrievechat]>=0.2.3) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers->pyautogen[retrievechat]>=0.2.3) (3.1.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers->pyautogen[retrievechat]>=0.2.3) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers->pyautogen[retrievechat]>=0.2.3) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers->pyautogen[retrievechat]>=0.2.3) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers->pyautogen[retrievechat]>=0.2.3) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers->pyautogen[retrievechat]>=0.2.3) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers->pyautogen[retrievechat]>=0.2.3) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers->pyautogen[retrievechat]>=0.2.3) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers->pyautogen[retrievechat]>=0.2.3) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers->pyautogen[retrievechat]>=0.2.3) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers->pyautogen[retrievechat]>=0.2.3) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers->pyautogen[retrievechat]>=0.2.3) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers->pyautogen[retrievechat]>=0.2.3) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence-transformers->pyautogen[retrievechat]>=0.2.3) (12.3.101)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers->pyautogen[retrievechat]>=0.2.3) (0.4.2)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from typer>=0.9.0->chromadb->pyautogen[retrievechat]>=0.2.3) (8.1.7)\n",
      "Requirement already satisfied: httptools>=0.5.0 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb->pyautogen[retrievechat]>=0.2.3) (0.6.1)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb->pyautogen[retrievechat]>=0.2.3) (0.19.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb->pyautogen[retrievechat]>=0.2.3) (0.21.0)\n",
      "Requirement already satisfied: websockets>=10.4 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb->pyautogen[retrievechat]>=0.2.3) (12.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from stack-data->ipython->pyautogen[retrievechat]>=0.2.3) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from stack-data->ipython->pyautogen[retrievechat]>=0.2.3) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from stack-data->ipython->pyautogen[retrievechat]>=0.2.3) (0.2.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb->pyautogen[retrievechat]>=0.2.3) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb->pyautogen[retrievechat]>=0.2.3) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb->pyautogen[retrievechat]>=0.2.3) (4.9)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from importlib-metadata<7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb->pyautogen[retrievechat]>=0.2.3) (3.17.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from coloredlogs->onnxruntime<2.0,>=1.15->fastembed==0.1.1->qdrant_client[fastembed]) (10.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers->pyautogen[retrievechat]>=0.2.3) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from sympy->onnxruntime<2.0,>=1.15->fastembed==0.1.1->qdrant_client[fastembed]) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb->pyautogen[retrievechat]>=0.2.3) (0.5.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install \"pyautogen[retrievechat]>=0.2.3\" \"flaml[automl]\" \"qdrant_client[fastembed]\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set your API Endpoint\n",
    "\n",
    "The [`config_list_from_json`](https://microsoft.github.io/autogen/docs/reference/oai/openai_utils#config_list_from_json) function loads a list of configurations from an environment variable or a json file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models to use:  ['ollama/mistral']\n"
     ]
    }
   ],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "\n",
    "import autogen\n",
    "from autogen.agentchat.contrib.qdrant_retrieve_user_proxy_agent import QdrantRetrieveUserProxyAgent\n",
    "from autogen.agentchat.contrib.retrieve_assistant_agent import RetrieveAssistantAgent\n",
    "\n",
    "# Accepted file formats for that can be stored in\n",
    "# a vector database instance\n",
    "from autogen.retrieve_utils import TEXT_FORMATS\n",
    "\n",
    "config_list = autogen.config_list_from_json(\n",
    "    env_or_file=\"OAI_CONFIG_LIST\",\n",
    "    file_location=\".\",\n",
    "    filter_dict={\n",
    "        \"model\": {\n",
    "            \"ollama/mistral\"\n",
    "        }\n",
    "    },\n",
    ")\n",
    "\n",
    "assert len(config_list) > 0\n",
    "print(\"models to use: \", [config_list[i][\"model\"] for i in range(len(config_list))])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It first looks for environment variable \"OAI_CONFIG_LIST\" which needs to be a valid json string. If that variable is not found, it then looks for a json file named \"OAI_CONFIG_LIST\". It filters the configs by models (you can filter by other keys as well). Only the gpt-4 and gpt-3.5-turbo models are kept in the list based on the filter condition.\n",
    "\n",
    "The config list looks like the following:\n",
    "```python\n",
    "config_list = [\n",
    "    {\n",
    "        'model': 'gpt-4',\n",
    "        'api_key': '<your OpenAI API key here>',\n",
    "    },\n",
    "    {\n",
    "        'model': 'gpt-4',\n",
    "        'api_key': '<your Azure OpenAI API key here>',\n",
    "        'base_url': '<your Azure OpenAI API base here>',\n",
    "        'api_type': 'azure',\n",
    "        'api_version': '2023-06-01-preview',\n",
    "    },\n",
    "    {\n",
    "        'model': 'gpt-3.5-turbo',\n",
    "        'api_key': '<your Azure OpenAI API key here>',\n",
    "        'base_url': '<your Azure OpenAI API base here>',\n",
    "        'api_type': 'azure',\n",
    "        'api_version': '2023-06-01-preview',\n",
    "    },\n",
    "]\n",
    "```\n",
    "\n",
    "If you open this notebook in colab, you can upload your files by clicking the file icon on the left panel and then choose \"upload file\" icon.\n",
    "\n",
    "You can set the value of config_list in other ways you prefer, e.g., loading from a YAML file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accepted file formats for `docs_path`:\n",
      "['txt', 'json', 'csv', 'tsv', 'md', 'html', 'htm', 'rtf', 'rst', 'jsonl', 'log', 'xml', 'yaml', 'yml', 'pdf']\n"
     ]
    }
   ],
   "source": [
    "print(\"Accepted file formats for `docs_path`:\")\n",
    "print(TEXT_FORMATS)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct agents for RetrieveChat\n",
    "\n",
    "We start by initializing the `RetrieveAssistantAgent` and `QdrantRetrieveUserProxyAgent`. The system message needs to be set to \"You are a helpful assistant.\" for RetrieveAssistantAgent. The detailed instructions are given in the user message. Later we will use the `QdrantRetrieveUserProxyAgent.generate_init_prompt` to combine the instructions and a retrieval augmented generation task for an initial prompt to be sent to the LLM assistant.\n",
    "\n",
    "### You can find the list of all the embedding models supported by Qdrant [here](https://qdrant.github.io/fastembed/examples/Supported_Models/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages/autogen/agentchat/user_proxy_agent.py:82: UserWarning: Using None to signal a default code_execution_config is deprecated. Use {} to use default or False to disable code execution.\n",
      "  super().__init__(\n"
     ]
    }
   ],
   "source": [
    "# 1. create an RetrieveAssistantAgent instance named \"assistant\"\n",
    "assistant = RetrieveAssistantAgent(\n",
    "    name=\"assistant\",\n",
    "    system_message=\"You are a helpful assistant.\",\n",
    "    llm_config={\n",
    "        \"timeout\": 600,\n",
    "        \"cache_seed\": 42,\n",
    "        \"config_list\": config_list,\n",
    "    },\n",
    ")\n",
    "\n",
    "# 2. create the QdrantRetrieveUserProxyAgent instance named \"ragproxyagent\"\n",
    "# By default, the human_input_mode is \"ALWAYS\", which means the agent will ask for human input at every step. We set it to \"NEVER\" here.\n",
    "# `docs_path` is the path to the docs directory. It can also be the path to a single file, or the url to a single file. By default,\n",
    "# it is set to None, which works only if the collection is already created.\n",
    "#\n",
    "# Here we generated the documentations from FLAML's docstrings. Not needed if you just want to try this notebook but not to reproduce the\n",
    "# outputs. Clone the FLAML (https://github.com/microsoft/FLAML) repo and navigate to its website folder. Pip install and run `pydoc-markdown`\n",
    "# and it will generate folder `reference` under `website/docs`.\n",
    "#\n",
    "# `task` indicates the kind of task we're working on. In this example, it's a `code` task.\n",
    "# `chunk_token_size` is the chunk token size for the retrieve chat. By default, it is set to `max_tokens * 0.6`, here we set it to 2000.\n",
    "# We use an in-memory QdrantClient instance here. Not recommended for production.\n",
    "# Get the installation instructions here: https://qdrant.tech/documentation/guides/installation/\n",
    "ragproxyagent = QdrantRetrieveUserProxyAgent(\n",
    "    name=\"ragproxyagent\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    max_consecutive_auto_reply=10,\n",
    "    retrieve_config={\n",
    "        \"task\": \"code\",\n",
    "        \"docs_path\": \"https://github.com/microsoft/FLAML/tree/main/website/docs\",  # change this to your own path, such as https://raw.githubusercontent.com/microsoft/autogen/main/README.md\n",
    "        \"chunk_token_size\": 2000,\n",
    "        \"model\": config_list[0][\"model\"],\n",
    "        \"client\": QdrantClient(\":memory:\"),\n",
    "        \"embedding_model\": \"BAAI/bge-small-en-v1.5\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"example-1\"></a>\n",
    "### Example 1\n",
    "\n",
    "[back to top](#toc)\n",
    "\n",
    "Use RetrieveChat to answer a question and ask for human-in-loop feedbacks.\n",
    "\n",
    "Problem: Is there a function named `tune_automl` in FLAML?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to create collection.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model ollama/mistral not found. Using cl100k_base encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mAdding doc_id 0 to context.\u001b[0m\n",
      "\u001b[33mragproxyagent\u001b[0m (to assistant):\n",
      "\n",
      "You're a retrieve augmented coding assistant. You answer user's questions based on your own knowledge and the\n",
      "context provided by the user.\n",
      "If you can't answer the question with or without the current context, you should reply exactly `UPDATE CONTEXT`.\n",
      "For code generation, you must obey the following rules:\n",
      "Rule 1. You MUST NOT install any packages because all the packages needed are already installed.\n",
      "Rule 2. You must follow the formats below to write your code:\n",
      "```language\n",
      "# your code\n",
      "```\n",
      "\n",
      "User's question is: Is there a function called tune_automl?\n",
      "\n",
      "Context is: {\"payload\":{\"allShortcutsEnabled\":false,\"path\":\"website/docs\",\"repo\":{\"id\":289107293,\"defaultBranch\":\"main\",\"name\":\"FLAML\",\"ownerLogin\":\"microsoft\",\"currentUserCanPush\":false,\"isFork\":false,\"isEmpty\":false,\"createdAt\":\"2020-08-20T20:46:11.000Z\",\"ownerAvatar\":\"https://avatars.githubusercontent.com/u/6154722?v=4\",\"public\":true,\"private\":false,\"isOrgOwned\":true},\"currentUser\":null,\"refInfo\":{\"name\":\"main\",\"listCacheKey\":\"v0:1707269803.0\",\"canEdit\":false,\"refType\":\"branch\",\"currentOid\":\"0415638dd1e1d3149fb17fb8760520af975d16f6\"},\"tree\":{\"items\":[{\"name\":\"Examples\",\"path\":\"website/docs/Examples\",\"contentType\":\"directory\"},{\"name\":\"Use-Cases\",\"path\":\"website/docs/Use-Cases\",\"contentType\":\"directory\"},{\"name\":\"Contribute.md\",\"path\":\"website/docs/Contribute.md\",\"contentType\":\"file\"},{\"name\":\"FAQ.md\",\"path\":\"website/docs/FAQ.md\",\"contentType\":\"file\"},{\"name\":\"Getting-Started.md\",\"path\":\"website/docs/Getting-Started.md\",\"contentType\":\"file\"},{\"name\":\"Installation.md\",\"path\":\"website/docs/Installation.md\",\"contentType\":\"file\"},{\"name\":\"Research.md\",\"path\":\"website/docs/Research.md\",\"contentType\":\"file\"}],\"templateDirectorySuggestionUrl\":null,\"readme\":null,\"totalCount\":7,\"showBranchInfobar\":false},\"fileTree\":{\"website\":{\"items\":[{\"name\":\"blog\",\"path\":\"website/blog\",\"contentType\":\"directory\"},{\"name\":\"docs\",\"path\":\"website/docs\",\"contentType\":\"directory\"},{\"name\":\"src\",\"path\":\"website/src\",\"contentType\":\"directory\"},{\"name\":\"static\",\"path\":\"website/static\",\"contentType\":\"directory\"},{\"name\":\".gitignore\",\"path\":\"website/.gitignore\",\"contentType\":\"file\"},{\"name\":\"README.md\",\"path\":\"website/README.md\",\"contentType\":\"file\"},{\"name\":\"babel.config.js\",\"path\":\"website/babel.config.js\",\"contentType\":\"file\"},{\"name\":\"docusaurus.config.js\",\"path\":\"website/docusaurus.config.js\",\"contentType\":\"file\"},{\"name\":\"package.json\",\"path\":\"website/package.json\",\"contentType\":\"file\"},{\"name\":\"pydoc-markdown.yml\",\"path\":\"website/pydoc-markdown.yml\",\"contentType\":\"file\"},{\"name\":\"sidebars.js\",\"path\":\"website/sidebars.js\",\"contentType\":\"file\"},{\"name\":\"yarn.lock\",\"path\":\"website/yarn.lock\",\"contentType\":\"file\"}],\"totalCount\":12},\"\":{\"items\":[{\"name\":\".devcontainer\",\"path\":\".devcontainer\",\"contentType\":\"directory\"},{\"name\":\".github\",\"path\":\".github\",\"contentType\":\"directory\"},{\"name\":\"flaml\",\"path\":\"flaml\",\"contentType\":\"directory\"},{\"name\":\"notebook\",\"path\":\"notebook\",\"contentType\":\"directory\"},{\"name\":\"test\",\"path\":\"test\",\"contentType\":\"directory\"},{\"name\":\"tutorials\",\"path\":\"tutorials\",\"contentType\":\"directory\"},{\"name\":\"website\",\"path\":\"website\",\"contentType\":\"directory\"},{\"name\":\".coveragerc\",\"path\":\".coveragerc\",\"contentType\":\"file\"},{\"name\":\".gitignore\",\"path\":\".gitignore\",\"contentType\":\"file\"},{\"name\":\".pre-commit-config.yaml\",\"path\":\".pre-commit-config.yaml\",\"contentType\":\"file\"},{\"name\":\"CITATION.cff\",\"path\":\"CITATION.cff\",\"contentType\":\"file\"},{\"name\":\"CODE_OF_CONDUCT.md\",\"path\":\"CODE_OF_CONDUCT.md\",\"contentType\":\"file\"},{\"name\":\"Dockerfile\",\"path\":\"Dockerfile\",\"contentType\":\"file\"},{\"name\":\"LICENSE\",\"path\":\"LICENSE\",\"contentType\":\"file\"},{\"name\":\"NOTICE.md\",\"path\":\"NOTICE.md\",\"contentType\":\"file\"},{\"name\":\"README.md\",\"path\":\"README.md\",\"contentType\":\"file\"},{\"name\":\"SECURITY.md\",\"path\":\"SECURITY.md\",\"contentType\":\"file\"},{\"name\":\"pyproject.toml\",\"path\":\"pyproject.toml\",\"contentType\":\"file\"},{\"name\":\"setup.py\",\"path\":\"setup.py\",\"contentType\":\"file\"}],\"totalCount\":19}},\"fileTreeProcessingTime\":5.451519,\"foldersToFetch\":[],\"treeExpanded\":true,\"symbolsExpanded\":false,\"csrf_tokens\":{\"/microsoft/FLAML/branches\":{\"post\":\"C14Et6l0JuYdLolorKZKPI1vhoZTn3zpAFWpcG__ZAOFXTLL0vY_Q238MB3fO5NZpLDhFFSl7QikppXrmgf78A\"},\"/microsoft/FLAML/branches/fetch_and_merge/main\":{\"post\":\"xaPrhMpHwDe0FGZUaqY1I1aZY4OOxHSzYZynOKN9nJbFY5uA4i6vZOy_n-O1XO-LYuq_-4_dVkazONypyoQ4kg\"},\"/microsoft/FLAML/branches/fetch_and_merge/main?discard_changes=true\":{\"post\":\"8dXNmyKPfThpjON_7o364q2mt0KR5RIwI9ct_HItRs3xFb2fCuYSazEnGsgxdyBKmdVrOpD8MMXxc1ZtG9TiyQ\"}}},\"title\":\"FLAML/website/docs at main Â· microsoft/FLAML\"}\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33massistant\u001b[0m (to ragproxyagent):\n",
      "\n",
      " Based on the context provided, I cannot find any evidence of a function called `tune_automl` in the given repository. Therefore, my answer is:\n",
      "\n",
      "```language\n",
      "# The context does not indicate the existence of a function called tune_automl\n",
      "```\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/twix/miniconda3/envs/genai_samples/lib/python3.10/site-packages/autogen/agentchat/conversable_agent.py:838: UserWarning: No summary_method provided or summary_method is not supported: \n",
      "  warnings.warn(\"No summary_method provided or summary_method is not supported: \")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatResult(chat_history=[{'content': 'You\\'re a retrieve augmented coding assistant. You answer user\\'s questions based on your own knowledge and the\\ncontext provided by the user.\\nIf you can\\'t answer the question with or without the current context, you should reply exactly `UPDATE CONTEXT`.\\nFor code generation, you must obey the following rules:\\nRule 1. You MUST NOT install any packages because all the packages needed are already installed.\\nRule 2. You must follow the formats below to write your code:\\n```language\\n# your code\\n```\\n\\nUser\\'s question is: Is there a function called tune_automl?\\n\\nContext is: {\"payload\":{\"allShortcutsEnabled\":false,\"path\":\"website/docs\",\"repo\":{\"id\":289107293,\"defaultBranch\":\"main\",\"name\":\"FLAML\",\"ownerLogin\":\"microsoft\",\"currentUserCanPush\":false,\"isFork\":false,\"isEmpty\":false,\"createdAt\":\"2020-08-20T20:46:11.000Z\",\"ownerAvatar\":\"https://avatars.githubusercontent.com/u/6154722?v=4\",\"public\":true,\"private\":false,\"isOrgOwned\":true},\"currentUser\":null,\"refInfo\":{\"name\":\"main\",\"listCacheKey\":\"v0:1707269803.0\",\"canEdit\":false,\"refType\":\"branch\",\"currentOid\":\"0415638dd1e1d3149fb17fb8760520af975d16f6\"},\"tree\":{\"items\":[{\"name\":\"Examples\",\"path\":\"website/docs/Examples\",\"contentType\":\"directory\"},{\"name\":\"Use-Cases\",\"path\":\"website/docs/Use-Cases\",\"contentType\":\"directory\"},{\"name\":\"Contribute.md\",\"path\":\"website/docs/Contribute.md\",\"contentType\":\"file\"},{\"name\":\"FAQ.md\",\"path\":\"website/docs/FAQ.md\",\"contentType\":\"file\"},{\"name\":\"Getting-Started.md\",\"path\":\"website/docs/Getting-Started.md\",\"contentType\":\"file\"},{\"name\":\"Installation.md\",\"path\":\"website/docs/Installation.md\",\"contentType\":\"file\"},{\"name\":\"Research.md\",\"path\":\"website/docs/Research.md\",\"contentType\":\"file\"}],\"templateDirectorySuggestionUrl\":null,\"readme\":null,\"totalCount\":7,\"showBranchInfobar\":false},\"fileTree\":{\"website\":{\"items\":[{\"name\":\"blog\",\"path\":\"website/blog\",\"contentType\":\"directory\"},{\"name\":\"docs\",\"path\":\"website/docs\",\"contentType\":\"directory\"},{\"name\":\"src\",\"path\":\"website/src\",\"contentType\":\"directory\"},{\"name\":\"static\",\"path\":\"website/static\",\"contentType\":\"directory\"},{\"name\":\".gitignore\",\"path\":\"website/.gitignore\",\"contentType\":\"file\"},{\"name\":\"README.md\",\"path\":\"website/README.md\",\"contentType\":\"file\"},{\"name\":\"babel.config.js\",\"path\":\"website/babel.config.js\",\"contentType\":\"file\"},{\"name\":\"docusaurus.config.js\",\"path\":\"website/docusaurus.config.js\",\"contentType\":\"file\"},{\"name\":\"package.json\",\"path\":\"website/package.json\",\"contentType\":\"file\"},{\"name\":\"pydoc-markdown.yml\",\"path\":\"website/pydoc-markdown.yml\",\"contentType\":\"file\"},{\"name\":\"sidebars.js\",\"path\":\"website/sidebars.js\",\"contentType\":\"file\"},{\"name\":\"yarn.lock\",\"path\":\"website/yarn.lock\",\"contentType\":\"file\"}],\"totalCount\":12},\"\":{\"items\":[{\"name\":\".devcontainer\",\"path\":\".devcontainer\",\"contentType\":\"directory\"},{\"name\":\".github\",\"path\":\".github\",\"contentType\":\"directory\"},{\"name\":\"flaml\",\"path\":\"flaml\",\"contentType\":\"directory\"},{\"name\":\"notebook\",\"path\":\"notebook\",\"contentType\":\"directory\"},{\"name\":\"test\",\"path\":\"test\",\"contentType\":\"directory\"},{\"name\":\"tutorials\",\"path\":\"tutorials\",\"contentType\":\"directory\"},{\"name\":\"website\",\"path\":\"website\",\"contentType\":\"directory\"},{\"name\":\".coveragerc\",\"path\":\".coveragerc\",\"contentType\":\"file\"},{\"name\":\".gitignore\",\"path\":\".gitignore\",\"contentType\":\"file\"},{\"name\":\".pre-commit-config.yaml\",\"path\":\".pre-commit-config.yaml\",\"contentType\":\"file\"},{\"name\":\"CITATION.cff\",\"path\":\"CITATION.cff\",\"contentType\":\"file\"},{\"name\":\"CODE_OF_CONDUCT.md\",\"path\":\"CODE_OF_CONDUCT.md\",\"contentType\":\"file\"},{\"name\":\"Dockerfile\",\"path\":\"Dockerfile\",\"contentType\":\"file\"},{\"name\":\"LICENSE\",\"path\":\"LICENSE\",\"contentType\":\"file\"},{\"name\":\"NOTICE.md\",\"path\":\"NOTICE.md\",\"contentType\":\"file\"},{\"name\":\"README.md\",\"path\":\"README.md\",\"contentType\":\"file\"},{\"name\":\"SECURITY.md\",\"path\":\"SECURITY.md\",\"contentType\":\"file\"},{\"name\":\"pyproject.toml\",\"path\":\"pyproject.toml\",\"contentType\":\"file\"},{\"name\":\"setup.py\",\"path\":\"setup.py\",\"contentType\":\"file\"}],\"totalCount\":19}},\"fileTreeProcessingTime\":5.451519,\"foldersToFetch\":[],\"treeExpanded\":true,\"symbolsExpanded\":false,\"csrf_tokens\":{\"/microsoft/FLAML/branches\":{\"post\":\"C14Et6l0JuYdLolorKZKPI1vhoZTn3zpAFWpcG__ZAOFXTLL0vY_Q238MB3fO5NZpLDhFFSl7QikppXrmgf78A\"},\"/microsoft/FLAML/branches/fetch_and_merge/main\":{\"post\":\"xaPrhMpHwDe0FGZUaqY1I1aZY4OOxHSzYZynOKN9nJbFY5uA4i6vZOy_n-O1XO-LYuq_-4_dVkazONypyoQ4kg\"},\"/microsoft/FLAML/branches/fetch_and_merge/main?discard_changes=true\":{\"post\":\"8dXNmyKPfThpjON_7o364q2mt0KR5RIwI9ct_HItRs3xFb2fCuYSazEnGsgxdyBKmdVrOpD8MMXxc1ZtG9TiyQ\"}}},\"title\":\"FLAML/website/docs at main Â· microsoft/FLAML\"}\\n\\n', 'role': 'assistant'}, {'content': ' Based on the context provided, I cannot find any evidence of a function called `tune_automl` in the given repository. Therefore, my answer is:\\n\\n```language\\n# The context does not indicate the existence of a function called tune_automl\\n```', 'role': 'user'}], summary='', cost=({'total_cost': 0, 'ollama/mistral': {'cost': 0, 'prompt_tokens': 1605, 'completion_tokens': 58, 'total_tokens': 1663}}, {'total_cost': 0, 'ollama/mistral': {'cost': 0, 'prompt_tokens': 1605, 'completion_tokens': 58, 'total_tokens': 1663}}), human_input=[])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reset the assistant. Always reset the assistant before starting a new conversation.\n",
    "assistant.reset()\n",
    "\n",
    "qa_problem = \"Is there a function called tune_automl?\"\n",
    "ragproxyagent.initiate_chat(assistant, problem=qa_problem)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"example-2\"></a>\n",
    "### Example 2\n",
    "\n",
    "[back to top](#toc)\n",
    "\n",
    "Use RetrieveChat to answer a question that is not related to code generation.\n",
    "\n",
    "Problem: Who is the author of FLAML?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model ollama/mistral not found. Using cl100k_base encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mAdding doc_id 0 to context.\u001b[0m\n",
      "\u001b[33mragproxyagent\u001b[0m (to assistant):\n",
      "\n",
      "You're a retrieve augmented coding assistant. You answer user's questions based on your own knowledge and the\n",
      "context provided by the user.\n",
      "If you can't answer the question with or without the current context, you should reply exactly `UPDATE CONTEXT`.\n",
      "For code generation, you must obey the following rules:\n",
      "Rule 1. You MUST NOT install any packages because all the packages needed are already installed.\n",
      "Rule 2. You must follow the formats below to write your code:\n",
      "```language\n",
      "# your code\n",
      "```\n",
      "\n",
      "User's question is: Who is the author of FLAML?\n",
      "\n",
      "Context is: {\"payload\":{\"allShortcutsEnabled\":false,\"path\":\"website/docs\",\"repo\":{\"id\":289107293,\"defaultBranch\":\"main\",\"name\":\"FLAML\",\"ownerLogin\":\"microsoft\",\"currentUserCanPush\":false,\"isFork\":false,\"isEmpty\":false,\"createdAt\":\"2020-08-20T20:46:11.000Z\",\"ownerAvatar\":\"https://avatars.githubusercontent.com/u/6154722?v=4\",\"public\":true,\"private\":false,\"isOrgOwned\":true},\"currentUser\":null,\"refInfo\":{\"name\":\"main\",\"listCacheKey\":\"v0:1707269803.0\",\"canEdit\":false,\"refType\":\"branch\",\"currentOid\":\"0415638dd1e1d3149fb17fb8760520af975d16f6\"},\"tree\":{\"items\":[{\"name\":\"Examples\",\"path\":\"website/docs/Examples\",\"contentType\":\"directory\"},{\"name\":\"Use-Cases\",\"path\":\"website/docs/Use-Cases\",\"contentType\":\"directory\"},{\"name\":\"Contribute.md\",\"path\":\"website/docs/Contribute.md\",\"contentType\":\"file\"},{\"name\":\"FAQ.md\",\"path\":\"website/docs/FAQ.md\",\"contentType\":\"file\"},{\"name\":\"Getting-Started.md\",\"path\":\"website/docs/Getting-Started.md\",\"contentType\":\"file\"},{\"name\":\"Installation.md\",\"path\":\"website/docs/Installation.md\",\"contentType\":\"file\"},{\"name\":\"Research.md\",\"path\":\"website/docs/Research.md\",\"contentType\":\"file\"}],\"templateDirectorySuggestionUrl\":null,\"readme\":null,\"totalCount\":7,\"showBranchInfobar\":false},\"fileTree\":{\"website\":{\"items\":[{\"name\":\"blog\",\"path\":\"website/blog\",\"contentType\":\"directory\"},{\"name\":\"docs\",\"path\":\"website/docs\",\"contentType\":\"directory\"},{\"name\":\"src\",\"path\":\"website/src\",\"contentType\":\"directory\"},{\"name\":\"static\",\"path\":\"website/static\",\"contentType\":\"directory\"},{\"name\":\".gitignore\",\"path\":\"website/.gitignore\",\"contentType\":\"file\"},{\"name\":\"README.md\",\"path\":\"website/README.md\",\"contentType\":\"file\"},{\"name\":\"babel.config.js\",\"path\":\"website/babel.config.js\",\"contentType\":\"file\"},{\"name\":\"docusaurus.config.js\",\"path\":\"website/docusaurus.config.js\",\"contentType\":\"file\"},{\"name\":\"package.json\",\"path\":\"website/package.json\",\"contentType\":\"file\"},{\"name\":\"pydoc-markdown.yml\",\"path\":\"website/pydoc-markdown.yml\",\"contentType\":\"file\"},{\"name\":\"sidebars.js\",\"path\":\"website/sidebars.js\",\"contentType\":\"file\"},{\"name\":\"yarn.lock\",\"path\":\"website/yarn.lock\",\"contentType\":\"file\"}],\"totalCount\":12},\"\":{\"items\":[{\"name\":\".devcontainer\",\"path\":\".devcontainer\",\"contentType\":\"directory\"},{\"name\":\".github\",\"path\":\".github\",\"contentType\":\"directory\"},{\"name\":\"flaml\",\"path\":\"flaml\",\"contentType\":\"directory\"},{\"name\":\"notebook\",\"path\":\"notebook\",\"contentType\":\"directory\"},{\"name\":\"test\",\"path\":\"test\",\"contentType\":\"directory\"},{\"name\":\"tutorials\",\"path\":\"tutorials\",\"contentType\":\"directory\"},{\"name\":\"website\",\"path\":\"website\",\"contentType\":\"directory\"},{\"name\":\".coveragerc\",\"path\":\".coveragerc\",\"contentType\":\"file\"},{\"name\":\".gitignore\",\"path\":\".gitignore\",\"contentType\":\"file\"},{\"name\":\".pre-commit-config.yaml\",\"path\":\".pre-commit-config.yaml\",\"contentType\":\"file\"},{\"name\":\"CITATION.cff\",\"path\":\"CITATION.cff\",\"contentType\":\"file\"},{\"name\":\"CODE_OF_CONDUCT.md\",\"path\":\"CODE_OF_CONDUCT.md\",\"contentType\":\"file\"},{\"name\":\"Dockerfile\",\"path\":\"Dockerfile\",\"contentType\":\"file\"},{\"name\":\"LICENSE\",\"path\":\"LICENSE\",\"contentType\":\"file\"},{\"name\":\"NOTICE.md\",\"path\":\"NOTICE.md\",\"contentType\":\"file\"},{\"name\":\"README.md\",\"path\":\"README.md\",\"contentType\":\"file\"},{\"name\":\"SECURITY.md\",\"path\":\"SECURITY.md\",\"contentType\":\"file\"},{\"name\":\"pyproject.toml\",\"path\":\"pyproject.toml\",\"contentType\":\"file\"},{\"name\":\"setup.py\",\"path\":\"setup.py\",\"contentType\":\"file\"}],\"totalCount\":19}},\"fileTreeProcessingTime\":5.451519,\"foldersToFetch\":[],\"treeExpanded\":true,\"symbolsExpanded\":false,\"csrf_tokens\":{\"/microsoft/FLAML/branches\":{\"post\":\"C14Et6l0JuYdLolorKZKPI1vhoZTn3zpAFWpcG__ZAOFXTLL0vY_Q238MB3fO5NZpLDhFFSl7QikppXrmgf78A\"},\"/microsoft/FLAML/branches/fetch_and_merge/main\":{\"post\":\"xaPrhMpHwDe0FGZUaqY1I1aZY4OOxHSzYZynOKN9nJbFY5uA4i6vZOy_n-O1XO-LYuq_-4_dVkazONypyoQ4kg\"},\"/microsoft/FLAML/branches/fetch_and_merge/main?discard_changes=true\":{\"post\":\"8dXNmyKPfThpjON_7o364q2mt0KR5RIwI9ct_HItRs3xFb2fCuYSazEnGsgxdyBKmdVrOpD8MMXxc1ZtG9TiyQ\"}}},\"title\":\"FLAML/website/docs at main Â· microsoft/FLAML\"}\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33massistant\u001b[0m (to ragproxyagent):\n",
      "\n",
      " Based on the context provided, there is no information about the author of FLAML. Therefore, my response will be `UPDATE CONTEXT` to indicate that more information is needed to answer the question.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatResult(chat_history=[{'content': 'You\\'re a retrieve augmented coding assistant. You answer user\\'s questions based on your own knowledge and the\\ncontext provided by the user.\\nIf you can\\'t answer the question with or without the current context, you should reply exactly `UPDATE CONTEXT`.\\nFor code generation, you must obey the following rules:\\nRule 1. You MUST NOT install any packages because all the packages needed are already installed.\\nRule 2. You must follow the formats below to write your code:\\n```language\\n# your code\\n```\\n\\nUser\\'s question is: Who is the author of FLAML?\\n\\nContext is: {\"payload\":{\"allShortcutsEnabled\":false,\"path\":\"website/docs\",\"repo\":{\"id\":289107293,\"defaultBranch\":\"main\",\"name\":\"FLAML\",\"ownerLogin\":\"microsoft\",\"currentUserCanPush\":false,\"isFork\":false,\"isEmpty\":false,\"createdAt\":\"2020-08-20T20:46:11.000Z\",\"ownerAvatar\":\"https://avatars.githubusercontent.com/u/6154722?v=4\",\"public\":true,\"private\":false,\"isOrgOwned\":true},\"currentUser\":null,\"refInfo\":{\"name\":\"main\",\"listCacheKey\":\"v0:1707269803.0\",\"canEdit\":false,\"refType\":\"branch\",\"currentOid\":\"0415638dd1e1d3149fb17fb8760520af975d16f6\"},\"tree\":{\"items\":[{\"name\":\"Examples\",\"path\":\"website/docs/Examples\",\"contentType\":\"directory\"},{\"name\":\"Use-Cases\",\"path\":\"website/docs/Use-Cases\",\"contentType\":\"directory\"},{\"name\":\"Contribute.md\",\"path\":\"website/docs/Contribute.md\",\"contentType\":\"file\"},{\"name\":\"FAQ.md\",\"path\":\"website/docs/FAQ.md\",\"contentType\":\"file\"},{\"name\":\"Getting-Started.md\",\"path\":\"website/docs/Getting-Started.md\",\"contentType\":\"file\"},{\"name\":\"Installation.md\",\"path\":\"website/docs/Installation.md\",\"contentType\":\"file\"},{\"name\":\"Research.md\",\"path\":\"website/docs/Research.md\",\"contentType\":\"file\"}],\"templateDirectorySuggestionUrl\":null,\"readme\":null,\"totalCount\":7,\"showBranchInfobar\":false},\"fileTree\":{\"website\":{\"items\":[{\"name\":\"blog\",\"path\":\"website/blog\",\"contentType\":\"directory\"},{\"name\":\"docs\",\"path\":\"website/docs\",\"contentType\":\"directory\"},{\"name\":\"src\",\"path\":\"website/src\",\"contentType\":\"directory\"},{\"name\":\"static\",\"path\":\"website/static\",\"contentType\":\"directory\"},{\"name\":\".gitignore\",\"path\":\"website/.gitignore\",\"contentType\":\"file\"},{\"name\":\"README.md\",\"path\":\"website/README.md\",\"contentType\":\"file\"},{\"name\":\"babel.config.js\",\"path\":\"website/babel.config.js\",\"contentType\":\"file\"},{\"name\":\"docusaurus.config.js\",\"path\":\"website/docusaurus.config.js\",\"contentType\":\"file\"},{\"name\":\"package.json\",\"path\":\"website/package.json\",\"contentType\":\"file\"},{\"name\":\"pydoc-markdown.yml\",\"path\":\"website/pydoc-markdown.yml\",\"contentType\":\"file\"},{\"name\":\"sidebars.js\",\"path\":\"website/sidebars.js\",\"contentType\":\"file\"},{\"name\":\"yarn.lock\",\"path\":\"website/yarn.lock\",\"contentType\":\"file\"}],\"totalCount\":12},\"\":{\"items\":[{\"name\":\".devcontainer\",\"path\":\".devcontainer\",\"contentType\":\"directory\"},{\"name\":\".github\",\"path\":\".github\",\"contentType\":\"directory\"},{\"name\":\"flaml\",\"path\":\"flaml\",\"contentType\":\"directory\"},{\"name\":\"notebook\",\"path\":\"notebook\",\"contentType\":\"directory\"},{\"name\":\"test\",\"path\":\"test\",\"contentType\":\"directory\"},{\"name\":\"tutorials\",\"path\":\"tutorials\",\"contentType\":\"directory\"},{\"name\":\"website\",\"path\":\"website\",\"contentType\":\"directory\"},{\"name\":\".coveragerc\",\"path\":\".coveragerc\",\"contentType\":\"file\"},{\"name\":\".gitignore\",\"path\":\".gitignore\",\"contentType\":\"file\"},{\"name\":\".pre-commit-config.yaml\",\"path\":\".pre-commit-config.yaml\",\"contentType\":\"file\"},{\"name\":\"CITATION.cff\",\"path\":\"CITATION.cff\",\"contentType\":\"file\"},{\"name\":\"CODE_OF_CONDUCT.md\",\"path\":\"CODE_OF_CONDUCT.md\",\"contentType\":\"file\"},{\"name\":\"Dockerfile\",\"path\":\"Dockerfile\",\"contentType\":\"file\"},{\"name\":\"LICENSE\",\"path\":\"LICENSE\",\"contentType\":\"file\"},{\"name\":\"NOTICE.md\",\"path\":\"NOTICE.md\",\"contentType\":\"file\"},{\"name\":\"README.md\",\"path\":\"README.md\",\"contentType\":\"file\"},{\"name\":\"SECURITY.md\",\"path\":\"SECURITY.md\",\"contentType\":\"file\"},{\"name\":\"pyproject.toml\",\"path\":\"pyproject.toml\",\"contentType\":\"file\"},{\"name\":\"setup.py\",\"path\":\"setup.py\",\"contentType\":\"file\"}],\"totalCount\":19}},\"fileTreeProcessingTime\":5.451519,\"foldersToFetch\":[],\"treeExpanded\":true,\"symbolsExpanded\":false,\"csrf_tokens\":{\"/microsoft/FLAML/branches\":{\"post\":\"C14Et6l0JuYdLolorKZKPI1vhoZTn3zpAFWpcG__ZAOFXTLL0vY_Q238MB3fO5NZpLDhFFSl7QikppXrmgf78A\"},\"/microsoft/FLAML/branches/fetch_and_merge/main\":{\"post\":\"xaPrhMpHwDe0FGZUaqY1I1aZY4OOxHSzYZynOKN9nJbFY5uA4i6vZOy_n-O1XO-LYuq_-4_dVkazONypyoQ4kg\"},\"/microsoft/FLAML/branches/fetch_and_merge/main?discard_changes=true\":{\"post\":\"8dXNmyKPfThpjON_7o364q2mt0KR5RIwI9ct_HItRs3xFb2fCuYSazEnGsgxdyBKmdVrOpD8MMXxc1ZtG9TiyQ\"}}},\"title\":\"FLAML/website/docs at main Â· microsoft/FLAML\"}\\n\\n', 'role': 'assistant'}, {'content': ' Based on the context provided, there is no information about the author of FLAML. Therefore, my response will be `UPDATE CONTEXT` to indicate that more information is needed to answer the question.', 'role': 'user'}], summary='', cost=({'total_cost': 0, 'ollama/mistral': {'cost': 0, 'prompt_tokens': 1470, 'completion_tokens': 41, 'total_tokens': 1511}}, {'total_cost': 0, 'ollama/mistral': {'cost': 0, 'prompt_tokens': 1470, 'completion_tokens': 41, 'total_tokens': 1511}}), human_input=[])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reset the assistant. Always reset the assistant before starting a new conversation.\n",
    "assistant.reset()\n",
    "\n",
    "qa_problem = \"Who is the author of FLAML?\"\n",
    "ragproxyagent.initiate_chat(assistant, problem=qa_problem)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
